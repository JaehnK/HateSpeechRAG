{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae9fd7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import List, Dict, Any\n",
    "from langchain.schema import Document\n",
    "\n",
    "from VectorStoreDao import VectorStoreDao\n",
    "from Embeddings import EmbeddingModelFactory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "abfe0437",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    원본 11개 컬럼을 6개 간소화 컬럼으로 변환\n",
    "    \n",
    "    Args:\n",
    "        df: 원본 데이터프레임\n",
    "        \n",
    "    Returns:\n",
    "        간소화된 메타데이터가 추가된 데이터프레임\n",
    "    \"\"\"\n",
    "    # 복사본 생성\n",
    "    result_df = df.copy()\n",
    "    \n",
    "    # 간소화 컬럼 생성\n",
    "    result_df['성별'] = df[['여성/가족', '남성', '성소수자']].max(axis=1)\n",
    "    result_df['정체성'] = df[['인종/국적', '지역', '종교']].max(axis=1)\n",
    "    result_df['연령'] = df['연령']\n",
    "    result_df['기타'] = df[['기타 혐오', '개인지칭']].max(axis=1)\n",
    "    result_df['욕설'] = df['악플/욕설']\n",
    "    result_df['혐오없음'] = df['clean']\n",
    "    \n",
    "    print(\"컬럼 변환 완료:\")\n",
    "    print(f\"- 성별: {result_df['성별'].sum()}개\")\n",
    "    print(f\"- 정체성: {result_df['정체성'].sum()}개\")\n",
    "    print(f\"- 연령: {result_df['연령'].sum()}개\")\n",
    "    print(f\"- 기타: {result_df['기타'].sum()}개\")\n",
    "    print(f\"- 욕설: {result_df['욕설'].sum()}개\")\n",
    "    print(f\"- 혐오없음: {result_df['혐오없음'].sum()}개\")\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2ecb78aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_documents_from_df(df: pd.DataFrame) -> List[Document]:\n",
    "    \"\"\"\n",
    "    데이터프레임을 Document 객체 리스트로 변환\n",
    "    \n",
    "    Args:\n",
    "        df: 간소화된 메타데이터가 포함된 데이터프레임\n",
    "        \n",
    "    Returns:\n",
    "        Document 객체 리스트\n",
    "    \"\"\"\n",
    "    documents = []\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        # 빈 문장 제외\n",
    "        if pd.isna(row['문장']) or row['문장'].strip() == '':\n",
    "            continue\n",
    "            \n",
    "        # Document 객체 생성\n",
    "        doc = Document(\n",
    "            page_content=str(row['문장']).strip(),\n",
    "            metadata={\n",
    "                \"성별\": int(row['성별']),\n",
    "                \"정체성\": int(row['정체성']),\n",
    "                \"연령\": int(row['연령']),\n",
    "                \"기타\": int(row['기타']),\n",
    "                \"욕설\": int(row['욕설']),\n",
    "                \"혐오없음\": int(row['혐오없음']),\n",
    "                \"row_index\": idx  # 원본 데이터 추적용\n",
    "            }\n",
    "        )\n",
    "        documents.append(doc)\n",
    "    \n",
    "    print(f\"Document 변환 완료: {len(documents)}개\")\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80037be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_vecstore(\n",
    "    df: pd.DataFrame,\n",
    "    persist_directory: str = \"./hate_speech_vectorstore\",\n",
    "    embedding_provider: str = \"openai\",\n",
    "    batch_size: int = 100,\n",
    "    clear_existing: bool = False\n",
    ") -> VectorStoreDao:\n",
    "    \"\"\"\n",
    "    데이터프레임을 벡터스토어에 업로드\n",
    "    \n",
    "    Args:\n",
    "        df: 혐오표현 데이터프레임\n",
    "        persist_directory: 벡터스토어 저장 경로\n",
    "        embedding_provider: 임베딩 모델 제공자 ('openai' 또는 'upstage')\n",
    "        batch_size: 배치 처리 크기\n",
    "        clear_existing: 기존 데이터 삭제 여부\n",
    "        \n",
    "    Returns:\n",
    "        VectorStoreDao 인스턴스\n",
    "    \"\"\"\n",
    "    print(\"=== 벡터스토어 업로드 시작 ===\")\n",
    "    \n",
    "    # 1. 컬럼 간소화\n",
    "    print(\"1. 컬럼 간소화 중...\")\n",
    "    processed_df = concat_columns(df)\n",
    "    \n",
    "    # 2. Document 변환\n",
    "    print(\"2. Document 객체 변환 중...\")\n",
    "    documents = create_documents_from_df(processed_df)\n",
    "    \n",
    "    if len(documents) == 0:\n",
    "        raise ValueError(\"변환된 문서가 없습니다. 데이터를 확인해주세요.\")\n",
    "    \n",
    "    # 3. DAO 초기화\n",
    "    print(\"3. VectorStoreDao 초기화 중...\")\n",
    "    embedding_model = EmbeddingModelFactory.create_embedding_model(embedding_provider)\n",
    "    dao = VectorStoreDao(\n",
    "        persist_directory=persist_directory,\n",
    "        embedding_model=embedding_model,\n",
    "        collection_name=\"hate_speech_collection\"\n",
    "    )\n",
    "    \n",
    "    # 4. 기존 데이터 처리\n",
    "    if clear_existing:\n",
    "        print(\"4. 기존 데이터 삭제 중...\")\n",
    "        try:\n",
    "            dao.clear_collection()\n",
    "        except:\n",
    "            print(\"   기존 컬렉션이 없거나 삭제 실패 (정상)\")\n",
    "    \n",
    "    # 5. 배치 업로드\n",
    "    print(f\"5. 벡터스토어 업로드 중... (배치 크기: {batch_size})\")\n",
    "    \n",
    "    total_batches = (len(documents) + batch_size - 1) // batch_size\n",
    "    \n",
    "    for i in range(0, len(documents), batch_size):\n",
    "        batch = documents[i:i + batch_size]\n",
    "        batch_num = (i // batch_size) + 1\n",
    "        \n",
    "        print(f\"   배치 {batch_num}/{total_batches}: {len(batch)}개 문서 처리 중...\")\n",
    "        \n",
    "        if i == 0:\n",
    "            # 첫 번째 배치는 create_vector_store로 생성\n",
    "            dao.create_vector_store(batch, force_recreate=True)\n",
    "        else:\n",
    "            # 나머지는 add_documents로 추가\n",
    "            dao.add_documents(batch)\n",
    "    \n",
    "    # 6. 완료 및 정보 출력\n",
    "    print(\"6. 업로드 완료!\")\n",
    "    dao.persist()\n",
    "    \n",
    "    info = dao.get_collection_info()\n",
    "    print(f\"=== 업로드 결과 ===\")\n",
    "    print(f\"총 문서 수: {info.get('document_count', 'N/A')}\")\n",
    "    print(f\"저장 경로: {info.get('persist_directory', 'N/A')}\")\n",
    "    print(f\"컬렉션명: {info.get('collection_name', 'N/A')}\")\n",
    "    \n",
    "    return dao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dba6fbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_search(dao: VectorStoreDao, test_queries: List[str] = None) -> None:\n",
    "    \"\"\"\n",
    "    벡터스토어 검색 테스트\n",
    "    \n",
    "    Args:\n",
    "        dao: VectorStoreDao 인스턴스\n",
    "        test_queries: 테스트할 쿼리 리스트\n",
    "    \"\"\"\n",
    "    if test_queries is None:\n",
    "        test_queries = [\n",
    "            \"여성을 비하하는 말\",\n",
    "            \"욕설이 포함된 문장\", \n",
    "            \"깨끗한 일반 문장\",\n",
    "            \"나이 관련 차별 표현\"\n",
    "        ]\n",
    "    \n",
    "    print(\"=== 검색 테스트 ===\")\n",
    "    \n",
    "    for query in test_queries:\n",
    "        print(f\"\\n쿼리: '{query}'\")\n",
    "        try:\n",
    "            results = dao.retrieve_documents(query, k=3, retriever_type=\"basic\")\n",
    "            \n",
    "            for i, doc in enumerate(results, 1):\n",
    "                print(f\"  {i}. {doc.page_content[:50]}...\")\n",
    "                print(f\"     메타데이터: {doc.metadata}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"  검색 오류: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9e4c9398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 크기: (15005, 12)\n",
      "컬럼: ['문장', '여성/가족', '남성', '성소수자', '인종/국적', '연령', '지역', '종교', '기타 혐오', '악플/욕설', 'clean', '개인지칭']\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"korean_unsmile_dataset/unsmile_train_v1.0.tsv\", sep =\"\\t\")\n",
    "print(f\"데이터 크기: {df.shape}\")\n",
    "print(f\"컬럼: {df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d58a8154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 벡터스토어 업로드 시작 ===\n",
      "1. 컬럼 간소화 중...\n",
      "컬럼 변환 완료:\n",
      "- 성별: 3963개\n",
      "- 정체성: 3644개\n",
      "- 연령: 603개\n",
      "- 기타: 851개\n",
      "- 욕설: 3143개\n",
      "- 혐오없음: 3739개\n",
      "2. Document 객체 변환 중...\n",
      "Document 변환 완료: 15005개\n",
      "3. VectorStoreDao 초기화 중...\n",
      "4. 기존 데이터 삭제 중...\n",
      "   기존 컬렉션이 없거나 삭제 실패 (정상)\n",
      "5. 벡터스토어 업로드 중... (배치 크기: 100)\n",
      "   배치 1/151: 100개 문서 처리 중...\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Collection expecting embedding with dimension of 1536, got 4096",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInvalidArgumentError\u001b[39m                      Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m dao = \u001b[43mupload_vecstore\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./hate_speech_vectorstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding_provider\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupstage\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclear_existing\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m      7\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 64\u001b[39m, in \u001b[36mupload_vecstore\u001b[39m\u001b[34m(df, persist_directory, embedding_provider, batch_size, clear_existing)\u001b[39m\n\u001b[32m     60\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   배치 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_num\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_batches\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(batch)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m개 문서 처리 중...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m i == \u001b[32m0\u001b[39m:\n\u001b[32m     63\u001b[39m     \u001b[38;5;66;03m# 첫 번째 배치는 create_vector_store로 생성\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m     \u001b[43mdao\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_vector_store\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     66\u001b[39m     \u001b[38;5;66;03m# 나머지는 add_documents로 추가\u001b[39;00m\n\u001b[32m     67\u001b[39m     dao.add_documents(batch)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/lab/hateSpeechRAG/VectorStoreDao.py:49\u001b[39m, in \u001b[36mVectorStoreDao.create_vector_store\u001b[39m\u001b[34m(self, documents)\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     42\u001b[39m \u001b[33;03m벡터스토어 생성 또는 기존 로드\u001b[39;00m\n\u001b[32m     43\u001b[39m \u001b[33;03m\u001b[39;00m\n\u001b[32m     44\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m     45\u001b[39m \u001b[33;03m    documents: 초기 문서 리스트 (새로 생성 시)\u001b[39;00m\n\u001b[32m     46\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m documents:\n\u001b[32m     48\u001b[39m     \u001b[38;5;66;03m# 새로운 벡터스토어 생성\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m     \u001b[38;5;28mself\u001b[39m.vector_store = \u001b[43mChroma\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[43m        \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membedding_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43membedding_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcollection_name\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m     \u001b[38;5;28mself\u001b[39m.documents = documents.copy()\n\u001b[32m     56\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m새로운 벡터스토어 생성 완료: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(documents)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m개 문서\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/youtube_api/lib/python3.13/site-packages/langchain_chroma/vectorstores.py:1371\u001b[39m, in \u001b[36mChroma.from_documents\u001b[39m\u001b[34m(cls, documents, embedding, ids, collection_name, persist_directory, host, port, headers, chroma_cloud_api_key, tenant, database, client_settings, client, collection_metadata, collection_configuration, ssl, **kwargs)\u001b[39m\n\u001b[32m   1369\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1370\u001b[39m     ids = [doc.id \u001b[38;5;28;01mif\u001b[39;00m doc.id \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(uuid.uuid4()) \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[32m-> \u001b[39m\u001b[32m1371\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1372\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1373\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m=\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1374\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1375\u001b[39m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1376\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1377\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1378\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhost\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1379\u001b[39m \u001b[43m    \u001b[49m\u001b[43mport\u001b[49m\u001b[43m=\u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1380\u001b[39m \u001b[43m    \u001b[49m\u001b[43mssl\u001b[49m\u001b[43m=\u001b[49m\u001b[43mssl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1381\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1382\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchroma_cloud_api_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchroma_cloud_api_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1383\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1384\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1385\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient_settings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1386\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1387\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcollection_metadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollection_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1388\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcollection_configuration\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollection_configuration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1389\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1390\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/youtube_api/lib/python3.13/site-packages/langchain_chroma/vectorstores.py:1304\u001b[39m, in \u001b[36mChroma.from_texts\u001b[39m\u001b[34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, host, port, headers, chroma_cloud_api_key, tenant, database, client_settings, client, collection_metadata, collection_configuration, ssl, **kwargs)\u001b[39m\n\u001b[32m   1296\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchromadb\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbatch_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_batches\n\u001b[32m   1298\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m create_batches(\n\u001b[32m   1299\u001b[39m         api=chroma_collection._client,\n\u001b[32m   1300\u001b[39m         ids=ids,\n\u001b[32m   1301\u001b[39m         metadatas=metadatas,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m   1302\u001b[39m         documents=texts,\n\u001b[32m   1303\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1304\u001b[39m         \u001b[43mchroma_collection\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1305\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1306\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1307\u001b[39m \u001b[43m            \u001b[49m\u001b[43mids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1308\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1309\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1310\u001b[39m     chroma_collection.add_texts(texts=texts, metadatas=metadatas, ids=ids)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/youtube_api/lib/python3.13/site-packages/langchain_chroma/vectorstores.py:630\u001b[39m, in \u001b[36mChroma.add_texts\u001b[39m\u001b[34m(self, texts, metadatas, ids, **kwargs)\u001b[39m\n\u001b[32m    628\u001b[39m ids_with_metadata = [ids[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m non_empty_ids]\n\u001b[32m    629\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m630\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_collection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupsert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    631\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m    632\u001b[39m \u001b[43m        \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43membeddings_with_metadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m    633\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtexts_with_metadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    634\u001b[39m \u001b[43m        \u001b[49m\u001b[43mids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mids_with_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    635\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    636\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    637\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mExpected metadata value to be\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/youtube_api/lib/python3.13/site-packages/chromadb/api/models/Collection.py:374\u001b[39m, in \u001b[36mCollection.upsert\u001b[39m\u001b[34m(self, ids, embeddings, metadatas, documents, images, uris)\u001b[39m\n\u001b[32m    354\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Update the embeddings, metadatas or documents for provided ids, or create them if they don't exist.\u001b[39;00m\n\u001b[32m    355\u001b[39m \n\u001b[32m    356\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    363\u001b[39m \u001b[33;03m    None\u001b[39;00m\n\u001b[32m    364\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    365\u001b[39m upsert_request = \u001b[38;5;28mself\u001b[39m._validate_and_prepare_upsert_request(\n\u001b[32m    366\u001b[39m     ids=ids,\n\u001b[32m    367\u001b[39m     embeddings=embeddings,\n\u001b[32m   (...)\u001b[39m\u001b[32m    371\u001b[39m     uris=uris,\n\u001b[32m    372\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m374\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_upsert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcollection_id\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mupsert_request\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mids\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m    \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mupsert_request\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43membeddings\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mupsert_request\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadatas\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m=\u001b[49m\u001b[43mupsert_request\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdocuments\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m    \u001b[49m\u001b[43muris\u001b[49m\u001b[43m=\u001b[49m\u001b[43mupsert_request\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muris\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    382\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/youtube_api/lib/python3.13/site-packages/chromadb/api/rust.py:464\u001b[39m, in \u001b[36mRustBindingsAPI._upsert\u001b[39m\u001b[34m(self, collection_id, ids, embeddings, metadatas, documents, uris, tenant, database)\u001b[39m\n\u001b[32m    452\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_upsert\u001b[39m(\n\u001b[32m    454\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    462\u001b[39m     database: \u001b[38;5;28mstr\u001b[39m = DEFAULT_DATABASE,\n\u001b[32m    463\u001b[39m ) -> \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m464\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbindings\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupsert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    465\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcollection_id\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    466\u001b[39m \u001b[43m        \u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    467\u001b[39m \u001b[43m        \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    468\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    469\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    470\u001b[39m \u001b[43m        \u001b[49m\u001b[43muris\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    471\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    472\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    473\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mInvalidArgumentError\u001b[39m: Collection expecting embedding with dimension of 1536, got 4096"
     ]
    }
   ],
   "source": [
    "dao = upload_vecstore(\n",
    "    df=df,\n",
    "    persist_directory=\"./hate_speech_vectorstore\",\n",
    "    embedding_provider=\"upstage\",\n",
    "    batch_size=100,\n",
    "    clear_existing=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "youtube_api",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
